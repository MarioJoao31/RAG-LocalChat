# ğŸ“š RAG Document Query Assistant

This project implements a modular **Retrieval-Augmented Generation (RAG)** pipeline with a user-friendly **Streamlit** interface. It allows you to ingest, chunk, embed, store, and query documents (PDF, DOCX, TXT) using local or cloud-based embedding models and a vector store. The system is built using **LangChain** and **LangSmith** for pipeline orchestration, observability, and experimentation.

---

## ğŸš€ Features

- ğŸ” **Document Loader** (PDF, DOCX, TXT)  
- ğŸ§  **Embedding Models** (Hugging Face, Google Gemini, Local)  
- ğŸ§¹ **Semantic Chunking** with `SemanticChunker`  
- ğŸ—‚ï¸ **Vector Store** via ChromaDB  
- ğŸ’¬ **Natural Language Query Interface** (Streamlit)  
- ğŸ”„ **Multiple Answer Generation Models** (switch dynamically in UI)  
- ğŸ”— **Google Drive Folder Linking** for document ingestion  
- ğŸ§ª **LangChain + LangSmith Integration** for modular pipelines and tracing  
- ğŸ§  **Feedback (Like/Dislike)** system for user-based reward signals and future retraining

---

## ğŸ§‘â€ğŸ’» How to Run

### 1. ğŸ”§ Install Requirements

```bash
pip install -r requirements.txt
```

### .env

```bash
GOOGLE_API_KEY=your_google_genai_api_key  # if using Google embeddings
LANGCHAIN_API_KEY=your_langchain_api_key
LANGCHAIN_TRACING_V2=true
```

### ğŸ—ƒï¸ Load and Process Docs

Make sure your input files are in the Docs/ folder.
Run your data prep pipeline (from rag_pipeline.py) once to initialize VectorDataBase/.

### ğŸ–¥ï¸ Launch the App

```bash
streamlit run app.py
```

---

## ğŸ§  Embedding Options

You can switch between:
 - âœ… Local Hugging Face model (sentence-transformers/all-MiniLM-L6-v2)
 - â˜ï¸ Google Generative AI (embedding-001)
 - ğŸ”— Easily extensible via embedder.py

---

## ğŸ¤– Answer Generation Models

You can switch between:
 - ğŸ’¡ Multiple model selection (LLM choices) directly from the UI
 - Easily pluggable using llm_router.py and LangChain agents

--- 
## â¤ï¸ Reward Feedback Feature

Users can provide feedback (ğŸ‘ Like / ğŸ‘ Dislike) on each response.
This feedback is stored for future use in fine-tuning or retraining the LLM components, enabling continuous improvement based on user preferences.

---
## ğŸ”— Google Drive Upload Setup

To enable file upload directly from Google Drive:

### 1. Go to [Google Cloud Console](https://console.cloud.google.com/)

### 2. Create a Project or Select an Existing One

### 3. Enable the Google Drive API
- Go to **APIs & Services â†’ Library**
- Search and enable **Google Drive API**

### 4. Create OAuth 2.0 Credentials
- Go to **APIs & Services â†’ Credentials**
- Click **Create Credentials â†’ OAuth client ID**
- Select **Desktop App**
- Click **Create**

### 5. Download `client_secrets.json`
- After creation, click the download icon
- Rename the file to `client_secrets.json`
- Place it in the project root directory

### 6. Run the Google Drive Integration Feature
Once the file is in place, your app can authenticate with Google and access your Drive documents.
